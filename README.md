# SuperVised-ML-Algorithms
 Machine Learning Model Evaluation Repository
This GitHub repository provides a comprehensive analysis of various machine learning models applied to a specific classification task. The models are evaluated based on their training accuracy, test accuracy, precision, recall, F1 score, and ROC AUC score. The dataset used for this evaluation is not explicitly mentioned, but the models are likely designed for a binary classification problem given the metrics provided.

Included Models:
Logistic Regression:

Training Accuracy: 85.31%
Test Accuracy: 82.50%
Test Precision: 86.96%
Test Recall: 64.52%
Test F1 Score: 74.07%
Test ROC AUC: 79.20%
Naive Bayes:

Training Accuracy: 89.69%
Test Accuracy: 85.00%
Test Precision: 88.00%
Test Recall: 70.97%
Test F1 Score: 78.57%
Test ROC AUC: 82.42%
K-Nearest Neighbors (KNN):

Training Accuracy: 93.75%
Test Accuracy: 90.00%
Test Precision: 92.59%
Test Recall: 80.65%
Test F1 Score: 86.21%
Test ROC AUC: 88.28%
Decision Tree:

Training Accuracy: 99.38%
Test Accuracy: 83.75%
Test Precision: 82.14%
Test Recall: 74.19%
Test F1 Score: 77.97%
Test ROC AUC: 81.99%
Support Vector Machine (SVM):

Training Accuracy: 90.63%
Test Accuracy: 90.00%
Test Precision: 89.66%
Test Recall: 83.87%
Test F1 Score: 86.67%
Test ROC AUC: 88.87%

Repository Structure:
code/: Contains the implementation of the machine learning models.
data/: Holds the dataset used for training and testing.
results/: Stores the detailed results and metrics obtained during model evaluation.

How to Use:
Clone the repository.
Navigate to the 'code/' directory.
Run the scripts to train and evaluate each model.
Explore the 'results/' directory for detailed metrics and analysis.
Feel free to contribute, report issues, or suggest improvements to enhance the quality of the models and the repository. Happy coding!




